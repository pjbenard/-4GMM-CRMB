{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as npl\n",
    "import scipy as sp\n",
    "import scipy.sparse.linalg as spspl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## offline procedure\n",
    "(not dependant of the problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def POD_offline_procedure(total_model_solver,training_set,tol,plot = False):\n",
    "    U_delta_list = []\n",
    "    for mu_loop in training_set:\n",
    "        if plot:\n",
    "            # coucou really ?? x) \n",
    "            coucou = total_model_solver(mu_loop,True)\n",
    "            plt.plot(coucou[0],coucou[1],label = str(mu_loop))\n",
    "            U_delta_list.append(coucou[1])\n",
    "        else:\n",
    "            U_delta_list.append(total_model_solver(mu_loop))\n",
    "            \n",
    "    if plot:\n",
    "        #plt.legend()\n",
    "        plt.title(\"all different solutions for mu in training_set\")\n",
    "        plt.show()\n",
    "        \n",
    "    U_delta = np.array(U_delta_list)\n",
    "    U,S,V = svd(U_delta)\n",
    "    cumul_relat_vp = 0\n",
    "    sum_vp = np.sum(S)\n",
    "    \n",
    "    for rank,vp in enumerate(S):\n",
    "        cumul_relat_vp += vp/sum_vp\n",
    "        if 1-cumul_relat_vp < tol:\n",
    "            tronk_rank = rank\n",
    "            break\n",
    "            \n",
    "    U_tr = U[:,:tronk_rank+1]\n",
    "    \n",
    "    return U_delta.T @ U_tr, 1-cumul_relat_vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd(U_delta):\n",
    "    \"\"\"\n",
    "    This is not a simple svd, it's a svd-based algorithm described in \n",
    "    \"Linear algebra box: Proper Orthogonal Decomposition (POD)\" p.33\n",
    "    \"This is a revolution\" - Steve Jobs lors de la keynote pour la svd 3GS le 9 janvier 2007\n",
    "    \"\"\"\n",
    "    N,M = U_delta.shape\n",
    "    wU = U_delta/np.sqrt(M)\n",
    "    U,s,V = npl.svd(wU,False)\n",
    "    S = s**2\n",
    "    return U,S,V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_set_creator(*args):\n",
    "    \"\"\"\n",
    "    args are a non-zero number of lists of size 3.\n",
    "    Example of use: we want the creation of an iteratable representing all possible elements on a n-dimensional grid\n",
    "    first dimension goes from a to b with c elements, then you pass \"[a,b,c]\" as a first argument.\n",
    "    return: n-dimensional grid on which you can iterate.\n",
    "    \n",
    "    \"\"\"\n",
    "    linspace_args = (np.linspace(arg[0],arg[1],arg[2]) for arg in args)\n",
    "    pools = [tuple(pool) for pool in linspace_args]\n",
    "    result = [[]]\n",
    "    for pool in pools:\n",
    "        result = [x+[y] for x in result for y in pool]\n",
    "    for prod in result:\n",
    "        yield tuple(prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_solver(mu,A_q,shape):\n",
    "    \"\"\"\n",
    "    from output of pre_computer and a mu: computes A_rb and f_rb and u_rb, the solution of A_rb.u_rb=f_rb\n",
    "    \"\"\"\n",
    "    A = A_q[1]\n",
    "    f = A_q[3]\n",
    "    for i in range(shape):\n",
    "        A += A_q[0][i]*mu[i]\n",
    "    for i in range(shape,len(mu)):\n",
    "        f += A_q[2][i-shape]*mu[i]\n",
    "    return npl.solve(A,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem-dependant part\n",
    "(solver is the true solver, pre_computes creates A_rb^q matrices and f_rb^q vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solver(mu,plot = False):\n",
    "    # 2 args\n",
    "    # mu = [lambda_0, T_0]\n",
    "    n = 5\n",
    "    N_diff = 2**n\n",
    "    x_diff_plot = np.linspace(0,1,N_diff+2)\n",
    "    x_diff = x_diff_plot[:-1]\n",
    "    f_diff = np.zeros(len(x_diff))\n",
    "    f_diff[0] = 1\n",
    "    \n",
    "    #construction de la matrice A en format sparse\n",
    "    tab_A_0 = [np.repeat([1,0], [N_diff//2,N_diff//2], 0),\n",
    "               np.repeat([0,-2,-1,0],[1,N_diff//2-1,1,N_diff//2],0),\n",
    "               np.repeat([0,1,0],[1,N_diff//2-1,N_diff//2],0)]\n",
    "    tab_A_1 = [np.repeat([0,((N_diff+2)**2)], [N_diff//2,N_diff//2], 0),\n",
    "               np.repeat([1,0,-((N_diff+2)**2),-2*((N_diff+2)**2)],[1,N_diff//2-1,1,N_diff//2],0),\n",
    "               np.repeat([0,((N_diff+2)**2)],[N_diff//2,N_diff//2],0)]\n",
    "    #print(N_diff+1,len(tab_A_0[0]),len(tab_A_0[1]),len(tab_A_0[2]),\"\\n\",len(tab_A_1[0]),len(tab_A_1[1]),len(tab_A_1[2]))\n",
    "    A_0 = sp.sparse.diags(tab_A_0,[-1,0,1],(N_diff+1,N_diff+1))*((N_diff+2)**2)\n",
    "    A_1 = sp.sparse.diags(tab_A_1,[-1,0,1],(N_diff+1,N_diff+1))\n",
    "    #NPA_0 = A_0.todense()\n",
    "    #NPA_1 = A_1.todense()\n",
    "    #print(NPA_0+NPA_1)\n",
    "    #print(NPA_1)\n",
    "\n",
    "    #print(mu)\n",
    "    A = A_1 + mu[0]*A_0\n",
    "    f = mu[1] * f_diff\n",
    "    #résolution des diff finies (Au=f)\n",
    "    U_diff = spspl.spsolve(A,f)\n",
    "\n",
    "    #préparation au plot\n",
    "    U_diff_plot = np.zeros(N_diff+2)\n",
    "    U_diff_plot[:-1] = U_diff\n",
    "    \n",
    "    if plot:\n",
    "        return x_diff_plot, U_diff_plot\n",
    "    \n",
    "    return U_diff_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#résolution par diff finies\n",
    "def pre_computer(Base):\n",
    "    \"\"\"\n",
    "    pre_computer take as input a reduced_base and pre_computes all quantities used for a reduced_solver.\n",
    "    output: [[A_rb^q](0<= i <=n1),A_rb^0,[f_rb^q](0<= i <=n2),f_rb^0],n\n",
    "    with A_rb = sum_(i in 0..n1){ mu[i]*A_rb^(q_1)_i } + A_rb^0\n",
    "    and  f_rb = sum_(i in n1+1..n2){ mu[i]*f_rb^(q_1)_i } + f_rb^0\n",
    "            n = n1+1\n",
    "    \"\"\"\n",
    "    n = 5\n",
    "    N_diff = 2**n\n",
    "    f_diff = np.zeros(N_diff+2)\n",
    "    f_diff[0] = 1\n",
    "    \n",
    "    #construction des matrices A en format sparse\n",
    "    tab_A_0 = [np.repeat([1,0],[N_diff//2,N_diff//2+1],0),np.repeat([0,-2,-1,0],[1,N_diff//2-1,1,N_diff//2+1],0),np.repeat([0,1,0],[1,N_diff//2-1,N_diff//2+1],0)]\n",
    "    tab_A_1 = [np.repeat([0,((N_diff+2)**2),0],[N_diff//2,N_diff//2,1],0),np.repeat([1,0,-((N_diff+2)**2),-2*((N_diff+2)**2),1],[1,N_diff//2-1,1,N_diff//2,1],0),np.repeat([0,((N_diff+2)**2)],[N_diff//2,N_diff//2+1],0)]\n",
    "    A_0 = sp.sparse.diags(tab_A_0,[-1,0,1],(N_diff+2,N_diff+2))*((N_diff+2)**2)\n",
    "    A_1 = sp.sparse.diags(tab_A_1,[-1,0,1],(N_diff+2,N_diff+2))\n",
    "    \n",
    "    #A = A_1 + mu[0]*A_0\n",
    "    #f = mu[1] * f_diff\n",
    "    return [[Base.T @ A_0.todense() @ Base],\n",
    "            Base.T @ A_1.todense() @ Base ,\n",
    "            [Base.T @ f_diff],\n",
    "            Base.T @ np.zeros_like(f_diff)], 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### computes POD_Base\n",
    "T0 = np.array([1,50,50])\n",
    "T1 = np.array([1,5,100])\n",
    "training_set = training_set_creator(T0,T1)\n",
    "Base, error = POD_offline_procedure(solver,training_set,0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### From Base, fast evaluates u_rb(mu_test)\n",
    "A_q,shape = pre_computer(Base)\n",
    "mu_test = (0.28,40)\n",
    "U_rb = reduced_solver(mu_test,A_q,shape)\n",
    "X,U_true = solver(mu_test,plot = True)\n",
    "plt.plot(X,U_true,label=\"true_sol\")\n",
    "plt.plot(X,Base.dot(U_rb),label=\"reduced_sol\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(np.sum(np.abs(U_true-Base.dot(U_rb))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ancien code\n",
    "(nothing useful now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dimension_not_allowed_error(Exception):\n",
    "    def __init__(self,l,k):\n",
    "        self.l = l\n",
    "        self.k = k\n",
    "    def __str__(self):\n",
    "        return \"An error has occured while adding a new vector of size \"+str(self.k)+\" in basis of space of size \"+str(self.l)\n",
    "\n",
    "class base_orthonormee:\n",
    "    \n",
    "    def __init__(self,l,ps):\n",
    "        self.Cardinal = 0\n",
    "        self.Length = l\n",
    "        self.Scalar_Product = ps\n",
    "        self.Basis_Set = np.zeros((self.Length,self.Cardinal))\n",
    "    \n",
    "    def add(self,v):\n",
    "        if self.Length != len(v):\n",
    "            raise dimension_not_allowed_error(self.Length,len(v))\n",
    "        v -= self.Scalar_Product(self.Basis_Set.T,self.Scalar_Product(self.Basis_Set,v))\n",
    "        self.Basis_Set = np.concatenate((self.Basis_Set,v/np.sqrt(self.Scalar_Product(v,v))),axis=1)\n",
    "        self.Cardinal += 1\n",
    "    \n",
    "    def matrix(self):\n",
    "        return self.Basis_Set\n",
    "    \n",
    "    def show(self):\n",
    "        print(\"vector length : \",self.Length)\n",
    "        print(\"cardinal : \",self.Cardinal)\n",
    "        print(\"matrix : \",self.Basis_Set)\n",
    "\n",
    "def offline_procedure(total_model_solver,reduced_basis_solver,ps,pre_computing,training_set,tol,l):\n",
    "    \"\"\" \n",
    "    this function takes the problem and a sample of the parameter space and computes the reduced basis\n",
    "    (following greedy algorithm steps) that approximates the space (V_delta) so that the maximum error is less than the tolerance.\n",
    "    \n",
    "        function \"total model solver\" is the true solver.\n",
    "                                                Input: mu\n",
    "                                                Output: u_delta(mu)\n",
    "        function \"reduced basis solver\" solves the linear system A^mu_rb . u^mu_rb = f^mu_rb\n",
    "                                                Input: mu, Ta, Tf (pre_computed elements of A and f)\n",
    "                                                Output: u_rb(mu), s_rb(mu) = nu(mu)\n",
    "        function \"ps\" is the scalar product for normalization and orthogonalization.\n",
    "                                                Input: 2 vectors\n",
    "                                                Output: scalar_product result\n",
    "        function \"pre computing\" performs the precomputing step\n",
    "                                                Input: V (current V_rb basis)\n",
    "                                                Ouput: Ta,Tf (na partial A-matrices and nf f-vectors from affine assumption)\n",
    "        array \"training set\" is the sample of the parameter space\n",
    "        \n",
    "        float \"tol\" is the tolerance for stopping criteria\n",
    "        \n",
    "        integer \"l\" determines current vector length\n",
    "        \n",
    "    \"\"\"\n",
    "    mu = training_set[0]\n",
    "    max_nu = np.Inf\n",
    "    V = base_orthonormee(l,ps)\n",
    "    while max_nu > tol:\n",
    "        #gram-schmidt pour que V ressemble à une base\n",
    "        V.add(total_model_solver(mu))\n",
    "        #pre-computing\n",
    "        Ta,Tf = pre_computing(V.matrix)\n",
    "        #calcul de u_rb(mu) pour tout les mu\n",
    "        max_nu = 0\n",
    "        for mu_loop in training_set :\n",
    "            u_rb,nu = reduced_basis_solver(Ta,Tf,mu_loop)\n",
    "            if max_nu < nu and nu > tol:\n",
    "                max_nu = nu\n",
    "                mu = mu_loop\n",
    "    return V\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ps(u,v):\n",
    "    return u.T.dot(v)\n",
    "def pre_computing(V):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test base orthonormee\n",
    "#v1 = np.zeros((3,1))\n",
    "#v2 = np.zeros((3,1))\n",
    "#v3 = np.zeros((3,1))\n",
    "#v1 = np.asarray([[1.],[1.],[1.]])\n",
    "#v2 = np.asarray([[1.],[-1.],[0.]])\n",
    "#v3 = np.asarray([[-1.],[-9.],[-9.]])\n",
    "#test = base_orthonormee(v1,ps)\n",
    "#test.show()\n",
    "#test.add(v2)\n",
    "#test.show()\n",
    "#test.add(v3)\n",
    "#test.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
